{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15ac08b1-830c-4165-a112-f7808652b5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "Device count: 0\n",
      "Device name: CPU\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3a3710f-ae0c-4144-b38d-b3649177f54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer and 8-bit model...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 8-bit quantization for VRAM savings and speed\u001b[39;00m\n\u001b[1;32m     19\u001b[0m bnb_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(load_in_8bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 21\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# automatically maps layers to GPU\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# inference mode\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded in 8-bit on device:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mnext\u001b[39m(model\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:604\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    603\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    610\u001b[0m )\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/modeling_utils.py:277\u001b[0m, in \u001b[0;36mrestore_default_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/modeling_utils.py:4884\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4875\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transformers_explicit_filename\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[1;32m   4876\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4877\u001b[0m     ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transformers_explicit_filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors.index.json\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   4878\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4879\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe transformers file in the config seems to be incorrect: it is neither a safetensors file \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4880\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(*.safetensors) nor a safetensors index file (*.safetensors.index.json): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4881\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransformers_explicit_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4882\u001b[0m         )\n\u001b[0;32m-> 4884\u001b[0m hf_quantizer, config, dtype, device_map \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_quantizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_agent\u001b[49m\n\u001b[1;32m   4886\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4889\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4890\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot combine Quantization and loading a model from a GGUF file, try again by making sure you did not passed a `quantization_config` or that you did not load a quantized model from the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4891\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/quantizers/auto.py:319\u001b[0m, in \u001b[0;36mget_hf_quantizer\u001b[0;34m(config, quantization_config, dtype, from_tf, from_flax, device_map, weights_only, user_agent)\u001b[0m\n\u001b[1;32m    316\u001b[0m     hf_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_dtype(dtype)\n\u001b[1;32m    327\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_device_map(device_map)\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_8bit.py:73\u001b[0m, in \u001b[0;36mBnb8BitHfQuantizer.validate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `bitsandbytes` 8-bit quantization requires Accelerate: `pip install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m     )\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_bitsandbytes_available(check_library_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe bitsandbytes library requires PyTorch but it was not found in your environment. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can install it with `pip install torch`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`"
     ]
    }
   ],
   "source": [
    "#DO NOT RUN THIS AS PART OF THE GAME\n",
    "#This first block is only for generating a useable structure for the game. \n",
    "#This code takes 20 hours to complete!!! (30 seconds determing 10 category ratings per noun).\n",
    "\n",
    "import torch\n",
    "import ast\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# -------------------------------\n",
    "# Load tokenizer and 8-bit model\n",
    "# -------------------------------\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "print(\"Loading tokenizer and 8-bit model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 8-bit quantization for VRAM savings and speed\n",
    "bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",          # automatically maps layers to GPU\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=False,\n",
    ")\n",
    "model.eval()  # inference mode\n",
    "\n",
    "print(\"Model loaded in 8-bit on device:\", next(model.parameters()).device)\n",
    "print(\"VRAM allocated (bytes):\", torch.cuda.memory_allocated(), \"reserved:\", torch.cuda.memory_reserved())\n",
    "\n",
    "# -------------------------------\n",
    "# Load nouns from file\n",
    "# -------------------------------\n",
    "nouns = []\n",
    "#with open(\"test_nouns.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "with open(\"noun_universe.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        word = line.strip()\n",
    "        if word:\n",
    "            nouns.append(word)\n",
    "print(f\"Loaded {len(nouns)} nouns\")\n",
    "\n",
    "# -------------------------------\n",
    "# Helper: extract only the first dictionary\n",
    "# -------------------------------\n",
    "def extract_first_dict(text):\n",
    "    \"\"\"Keep only the first {...} in the text.\"\"\"\n",
    "    start = text.find(\"{\")\n",
    "    if start == -1:\n",
    "        return \"\"\n",
    "    stack = 0\n",
    "    for i, c in enumerate(text[start:], start):\n",
    "        if c == \"{\":\n",
    "            stack += 1\n",
    "        elif c == \"}\":\n",
    "            stack -= 1\n",
    "            if stack == 0:\n",
    "                return text[start:i+1]\n",
    "    return text[start:]  # fallback\n",
    "\n",
    "# -------------------------------\n",
    "# Process nouns one by one\n",
    "# -------------------------------\n",
    "noun_structures = []\n",
    "\n",
    "for noun in nouns:\n",
    "    print(\"processing noun:\", noun)\n",
    "\n",
    "    # --- Original prompt preserved exactly + stricter instructions ---\n",
    "    full_prompt = (\n",
    "        \"You are an expert at categorizing nouns. You need to return to me a dictionary structure in python where the noun \"\n",
    "        \"that I give you contains a true or false value for various category questions. The questions are \"\n",
    "        \"1.) Is it alive? This answer should be stored in boolean variable is_alive. \"\n",
    "        \"2.) Is it an person? This answer should be stored in boolean variable is_person? \"\n",
    "        \"3.) Is it a place? stored in variable is_place \"\n",
    "        \"4.) Is it a thing? stored in variable is_thing \"\n",
    "        \"5.) Is it a plant? stored in variable is_plant \"\n",
    "        \"6.) Is it an animal? stored in variable is_animal \"\n",
    "        \"7.) Is it a tangible physical object? stored in variable is_physical? \"\n",
    "        \"8.) Is it a rock or mineral? stored in is_rock \"\n",
    "        \"9.) Is it a food? stored in is_food \"\n",
    "        \"10.) Is it man made? stored in is_man_made. \"\n",
    "        \"The last field in the structure should be name, where the value is just the name of the noun. \"\n",
    "        \"IMPORTANT: Only return the dictionary for the noun given. Do NOT include any other nouns, examples, or commentary. \"\n",
    "        \"Please output only the variable names and values within curly brackets as would appear in a python dictionary structure. \"\n",
    "        \"Dont write anything outside of the curly brackets. The name variable must have a value that is exactly the provided noun. \"\n",
    "        \"Do this for the noun: \" + noun\n",
    "    )\n",
    "\n",
    "    # --- Tokenize and move to GPU ---\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(next(model.parameters()).device)\n",
    "\n",
    "    # --- Generate output ---\n",
    "    with torch.inference_mode():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=500,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            num_beams=1,\n",
    "            use_cache=True,\n",
    "        )\n",
    "\n",
    "    # --- Decode and clean output ---\n",
    "    result_text = tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()\n",
    "    clean_output = result_text.strip().removeprefix(\"```python\").removesuffix(\"```\").strip()\n",
    "\n",
    "    # --- Extract only the first dictionary ---\n",
    "    clean_output = extract_first_dict(clean_output)\n",
    "\n",
    "    print(clean_output)\n",
    "\n",
    "    # --- Convert string to dict safely ---\n",
    "    try:\n",
    "        noun_dict = ast.literal_eval(clean_output)\n",
    "        noun_structures.append(noun_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing output for '{noun}': {e}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Save results to JSON file\n",
    "# -------------------------------\n",
    "output_filename = \"noun_structures.json\"\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(noun_structures, f, indent=4)\n",
    "\n",
    "print(f\"Saved {len(noun_structures)} noun structures to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03f979e-953e-4029-a82c-caf639d386b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1843 dictionary blocks\n",
      "‚úÖ Parsed 1843 valid noun structures\n",
      "‚ö†Ô∏è Failed to parse 0 blocks; indices saved to bad_blocks/original_block_<i>.txt\n",
      "Saved cleaned output to noun_structures_clean.json\n",
      "All blocks parsed successfully.\n"
     ]
    }
   ],
   "source": [
    "#DONT NEED TO RUN THIS UNLESS THE GENERATED FILE ABOVE CHANGES\n",
    "#Process the LLM output into JSON format (and clean up malformed outputs) and save to a file so that the \n",
    "#category determinations for each of the nouns can be used. \n",
    "\n",
    "import re\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "\n",
    "INPUT = \"noun_structs.jsonl\"   # change if needed\n",
    "OUTPUT = \"noun_structures_clean.json\"\n",
    "BAD_DIR = \"bad_blocks\"\n",
    "\n",
    "os.makedirs(BAD_DIR, exist_ok=True)\n",
    "\n",
    "with open(INPUT, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# --- Balanced-brace extractor (more robust than a simple regex) ---\n",
    "blocks = []\n",
    "stack = []\n",
    "start_idx = None\n",
    "for i, ch in enumerate(content):\n",
    "    if ch == \"{\":\n",
    "        if not stack:\n",
    "            start_idx = i\n",
    "        stack.append(ch)\n",
    "    elif ch == \"}\":\n",
    "        if stack:\n",
    "            stack.pop()\n",
    "            if not stack and start_idx is not None:\n",
    "                blocks.append(content[start_idx:i+1])\n",
    "                start_idx = None\n",
    "\n",
    "print(f\"Found {len(blocks)} dictionary blocks\")\n",
    "\n",
    "noun_structures = []\n",
    "failed_indices = []\n",
    "\n",
    "def aggressive_repair(s: str) -> str:\n",
    "    b = s\n",
    "\n",
    "    # remove weird control characters (keep normal whitespace)\n",
    "    b = re.sub(r\"[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f]\", \" \", b)\n",
    "\n",
    "    # fix underscore splits across newlines/spaces: is_\\nphysical or is_ physical -> is_physical\n",
    "    b = re.sub(r\"_\\s*\\n\\s*\", \"_\", b)\n",
    "    b = re.sub(r\"_\\s+\", \"_\", b)\n",
    "\n",
    "    # ensure there's a closing brace if missing (shouldn't happen with balanced extractor, but safe)\n",
    "    if b.count(\"{\") > b.count(\"}\"):\n",
    "        b = b + \"}\"\n",
    "\n",
    "    # collapse internal repeated whitespace around colons, commas, and braces for reliability\n",
    "    b = re.sub(r\"[ \\t]+\\:\", \":\", b)\n",
    "    b = re.sub(r\"\\:[ \\t]+\", \": \", b)\n",
    "    b = re.sub(r\"[ \\t]+\\,\", \",\", b)\n",
    "    b = re.sub(r\",\\s+\\}\", \"}\", b)  # remove trailing commas before closing brace\n",
    "\n",
    "    # convert single quotes to double quotes carefully:\n",
    "    #  - first, handle keys without quotes (see below)\n",
    "    #  - then replace single-quoted strings with double quotes\n",
    "    # But do NOT blindly replace every single-quote because contractions or escaped quotes might exist.\n",
    "    # We'll do a simple safe replacement for patterns like '...'\n",
    "    b = re.sub(r\"\\'([^']*?)\\'\", r'\"\\1\"', b)\n",
    "\n",
    "    # normalize booleans/None for JSON parse\n",
    "    b = re.sub(r\"\\bTrue\\b\", \"true\", b)\n",
    "    b = re.sub(r\"\\bFalse\\b\", \"false\", b)\n",
    "    b = re.sub(r\"\\bNone\\b\", \"null\", b)\n",
    "\n",
    "    # Quote unquoted keys: look for key identifiers followed by colon that are not quoted\n",
    "    # This looks for occurrences like  name: or  is_alive: and replaces with \"name\":\n",
    "    def _quote_keys(text):\n",
    "        # pattern: beginning-of-block or comma or whitespace, then key (letters/underscore/digits), optional spaces, colon\n",
    "        pattern = re.compile(r'(?P<prefix>[\\{\\s,])(?P<key>[A-Za-z_][A-Za-z0-9_]*)\\s*:')\n",
    "        # replace with prefix \"key\":\n",
    "        return pattern.sub(lambda m: f'{m.group(\"prefix\")}\"{m.group(\"key\")}\":', text)\n",
    "\n",
    "    b = _quote_keys(b)\n",
    "\n",
    "    # final cleanup: remove duplicate commas and trailing commas before closing brace\n",
    "    b = re.sub(r\",\\s*,\", \",\", b)\n",
    "    b = re.sub(r\",\\s*}\", \"}\", b)\n",
    "\n",
    "    # Trim\n",
    "    return b.strip()\n",
    "\n",
    "def try_parse(original: str, idx: int):\n",
    "    \"\"\"Try to parse block; return dict or None and save diagnostics files when failing.\"\"\"\n",
    "    orig = original\n",
    "    # First try as-is (JSON)\n",
    "    try:\n",
    "        return json.loads(orig)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Try ast.literal_eval on original (handles Python style dicts)\n",
    "    try:\n",
    "        val = ast.literal_eval(orig)\n",
    "        return val\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Save original to disk for inspection\n",
    "    with open(os.path.join(BAD_DIR, f\"original_block_{idx}.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(orig)\n",
    "\n",
    "    # Aggressive repair\n",
    "    repaired = aggressive_repair(orig)\n",
    "\n",
    "    # Save repaired attempt for visibility\n",
    "    with open(os.path.join(BAD_DIR, f\"repaired_block_{idx}.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(repaired)\n",
    "\n",
    "    # Try JSON on repaired\n",
    "    try:\n",
    "        return json.loads(repaired)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Try ast on repaired (convert json booleans back to Python)\n",
    "    try:\n",
    "        pystyle = repaired.replace(\"true\", \"True\").replace(\"false\", \"False\").replace(\"null\", \"None\")\n",
    "        return ast.literal_eval(pystyle)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # If still failing, record index and return None\n",
    "    failed_indices.append(idx)\n",
    "    return None\n",
    "\n",
    "# Parse all blocks\n",
    "for i, blk in enumerate(blocks):\n",
    "    parsed = try_parse(blk, i)\n",
    "    if isinstance(parsed, dict):\n",
    "        noun_structures.append(parsed)\n",
    "    else:\n",
    "        # keep going ‚Äî problem blocks have been written to bad_blocks/\n",
    "        continue\n",
    "\n",
    "print(f\"‚úÖ Parsed {len(noun_structures)} valid noun structures\")\n",
    "print(f\"‚ö†Ô∏è Failed to parse {len(failed_indices)} blocks; indices saved to {BAD_DIR}/original_block_<i>.txt\")\n",
    "\n",
    "# Save cleaned JSON\n",
    "with open(OUTPUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(noun_structures, f, indent=4)\n",
    "print(f\"Saved cleaned output to {OUTPUT}\")\n",
    "\n",
    "# Print first few failed indices for convenience\n",
    "if failed_indices:\n",
    "    print(\"Failed block indices (first 10):\", failed_indices[:10])\n",
    "    print(f\"Open {BAD_DIR}/original_block_<i>.txt and repaired_block_<i>.txt to inspect and edit manually if needed.\")\n",
    "else:\n",
    "    print(\"All blocks parsed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b64db32-9d09-4ee9-8a12-fe213ba30aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1843 noun structures.\n",
      "Error processing noun: {'island': {'is_alive': False, 'is_person': False, 'is_place': True, 'is_thing': True, 'is_plant': False, 'is_animal': False, 'is_physical': True, 'is_rock': False, 'is_food': False, 'is_man_made': False, 'name': 'island'}} -> 'name'\n",
      "Error processing noun: {'mt07': {'name': 'mt07', 'is_alive': False, 'is_person': False, 'is_place': False, 'is_thing': True, 'is_plant': False, 'is_animal': False, 'is_physical': True, 'is_rock': False, 'is_food': False, 'is_man_made': False}} -> 'name'\n",
      "\n",
      "=== Category Summary ===\n",
      "non physical things: 1 nouns\n",
      "people: 167 nouns\n",
      "animals: 317 nouns\n",
      "plants: 134 nouns\n",
      "random living things: 5 nouns\n",
      "places: 237 nouns\n",
      "foods: 170 nouns\n",
      "man made objects: 1097 nouns\n",
      "rocks: 125 nouns\n",
      "random uncategorized objects: 189 nouns\n",
      "\n",
      "‚úÖ Categorized noun lists saved to 'categorized_nouns.json'\n",
      "Category: non physical things\n",
      "  has: ['complexity']\n",
      "  is: ['a concept']\n",
      "\n",
      "Category: people\n",
      "  has: ['entertainment', 'influence', 'scientific impact', 'athletic ability', 'medical knowledge', 'sports scoring ability']\n",
      "  is: ['actor', 'athlete', 'STEM worker', 'profession']\n",
      "\n",
      "Category: animals\n",
      "  has: ['size', 'speed', 'aggressiveness', 'domesticatability']\n",
      "  is: ['mammal', 'bird', 'reptile', 'fish', 'amphibian']\n",
      "\n",
      "Category: plants\n",
      "  has: ['size', 'beauty', 'leaves', 'fruit']\n",
      "  is: ['flower', 'tree', 'general plant or bush']\n",
      "\n",
      "Category: random living things\n",
      "  has: ['size', 'speed']\n",
      "  is: ['air breathing', 'water breathing']\n",
      "\n",
      "Category: places\n",
      "  has: ['heat', 'extreme weather', 'size', 'cold', 'population', 'vegetation']\n",
      "  is: ['In the US', 'In the western US', 'In the Eastern US', 'One Specific Place']\n",
      "\n",
      "Category: foods\n",
      "  has: ['heat', 'preparation time', 'ingredients', 'savoriness', 'sweetness', 'saltiness']\n",
      "  is: ['natural', 'cooked', 'raw']\n",
      "\n",
      "Category: man made objects\n",
      "  has: ['softness', 'engineering', 'electrical', 'size', 'monetary value', 'simplicity']\n",
      "  is: ['tool', 'vehicle', 'toy', 'service', 'exercise', 'clothing']\n",
      "\n",
      "Category: rocks\n",
      "  has: ['hardness', 'brittleness', 'shine', 'beauty', 'darkness', 'monetary value']\n",
      "  is: ['rock', 'mineral', 'metal']\n",
      "\n",
      "Category: random uncategorized objects\n",
      "  has: ['size', 'complexity', 'entertainment']\n",
      "  is: ['tool', 'vehicle', 'toy', 'pokemon', 'concept']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DO NOT RUN THIS UNLESS REGENERATING PREVIOUS DATA\n",
    "#This block creates the tree structure for use in the game. THIS IS AN INTERMEDIATE STEP\n",
    "\n",
    "class CategoryNode:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.properties = {}        # can hold stats or metadata later\n",
    "        self.question_node = None   # pointer to a QuestionNode (if this category has one)\n",
    "        self.noun_list = []         # used if it's a leaf node (no questions below it)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"CategoryNode({self.name})\"\n",
    "\n",
    "\n",
    "class QuestionNode:\n",
    "    def __init__(self, question):\n",
    "        self.question = question\n",
    "        self.yes = None   # pointer to a CategoryNode\n",
    "        self.no = None    # pointer to a CategoryNode\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"QuestionNode({self.question})\"\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# Hardcoded tree construction begins here\n",
    "# ======================================\n",
    "\n",
    "# --- Leaf category nodes (endpoints with noun lists) ---\n",
    "non_physical_things = CategoryNode(\"non physical things\")\n",
    "people = CategoryNode(\"people\")\n",
    "animals = CategoryNode(\"animals\")\n",
    "plants = CategoryNode(\"plants\")\n",
    "random_living_things = CategoryNode(\"random living things\")\n",
    "places = CategoryNode(\"places\")\n",
    "foods = CategoryNode(\"foods\")\n",
    "man_made_objects = CategoryNode(\"man made objects\")\n",
    "rocks = CategoryNode(\"rocks\")\n",
    "random_uncategorized_objects = CategoryNode(\"random uncategorized objects\")\n",
    "\n",
    "# --- Internal category nodes ---\n",
    "physical_objects = CategoryNode(\"physical objects\")\n",
    "living_things = CategoryNode(\"living things\")\n",
    "non_living_things = CategoryNode(\"non living things\")\n",
    "non_people = CategoryNode(\"non people\")\n",
    "non_animals = CategoryNode(\"non animals\")\n",
    "non_places = CategoryNode(\"non places\")\n",
    "things = CategoryNode(\"things\")\n",
    "non_foods = CategoryNode(\"non-foods\")\n",
    "natural_things = CategoryNode(\"natural things\")\n",
    "\n",
    "# --- Question nodes ---\n",
    "q_is_tangible = QuestionNode(\"Is it physically tangible?\")\n",
    "q_is_alive = QuestionNode(\"Is it alive?\")\n",
    "q_is_person = QuestionNode(\"Is it a person?\")\n",
    "q_is_animal = QuestionNode(\"Is it an animal?\")\n",
    "q_is_plant = QuestionNode(\"Is it a plant?\")\n",
    "q_is_place = QuestionNode(\"Is it a place?\")\n",
    "q_is_thing = QuestionNode(\"Is it a thing?\")\n",
    "q_is_food = QuestionNode(\"Is it a food?\")\n",
    "q_is_man_made = QuestionNode(\"Is it man made?\")\n",
    "q_is_rock = QuestionNode(\"Is it a rock or mineral?\")\n",
    "\n",
    "# ====================================\n",
    "# Link everything according to the map\n",
    "# ====================================\n",
    "\n",
    "# Root node\n",
    "root = q_is_tangible\n",
    "\n",
    "# Tangible?\n",
    "q_is_tangible.yes = physical_objects\n",
    "q_is_tangible.no = non_physical_things\n",
    "\n",
    "# Physical objects ‚Üí Is it alive?\n",
    "physical_objects.question_node = q_is_alive\n",
    "q_is_alive.yes = living_things\n",
    "q_is_alive.no = non_living_things\n",
    "\n",
    "# Living things ‚Üí Is it a person?\n",
    "living_things.question_node = q_is_person\n",
    "q_is_person.yes = people\n",
    "q_is_person.no = non_people\n",
    "\n",
    "# Non-people ‚Üí Is it an animal?\n",
    "non_people.question_node = q_is_animal\n",
    "q_is_animal.yes = animals\n",
    "q_is_animal.no = non_animals\n",
    "\n",
    "# Non-animals ‚Üí Is it a plant?\n",
    "non_animals.question_node = q_is_plant\n",
    "q_is_plant.yes = plants\n",
    "q_is_plant.no = random_living_things\n",
    "\n",
    "# Non-living things ‚Üí Is it a place?\n",
    "non_living_things.question_node = q_is_place\n",
    "q_is_place.yes = places\n",
    "q_is_place.no = non_places\n",
    "\n",
    "# Non-places ‚Üí Is it a thing?\n",
    "non_places.question_node = q_is_thing\n",
    "q_is_thing.yes = things\n",
    "q_is_thing.no = non_physical_things  # loops back intentionally per spec\n",
    "\n",
    "# Things ‚Üí Is it a food?\n",
    "things.question_node = q_is_food\n",
    "q_is_food.yes = foods\n",
    "q_is_food.no = non_foods\n",
    "\n",
    "# Non-foods ‚Üí Is it man made?\n",
    "non_foods.question_node = q_is_man_made\n",
    "q_is_man_made.yes = man_made_objects\n",
    "q_is_man_made.no = natural_things\n",
    "\n",
    "# Natural things ‚Üí Is it a rock or mineral?\n",
    "natural_things.question_node = q_is_rock\n",
    "q_is_rock.yes = rocks\n",
    "q_is_rock.no = random_uncategorized_objects\n",
    "\n",
    "# ====================================\n",
    "# Tree summary helper (for inspection)\n",
    "# ====================================\n",
    "def print_tree(node, depth=0):\n",
    "    indent = \"  \" * depth\n",
    "    if isinstance(node, QuestionNode):\n",
    "        print(f\"{indent}Q: {node.question}\")\n",
    "        print(f\"{indent}  Yes ‚Üí {node.yes.name}\")\n",
    "        print(f\"{indent}  No  ‚Üí {node.no.name}\")\n",
    "        print_tree(node.yes, depth + 1)\n",
    "        print_tree(node.no, depth + 1)\n",
    "    elif isinstance(node, CategoryNode):\n",
    "        if node.question_node:\n",
    "            print(f\"{indent}Category: {node.name}\")\n",
    "            print_tree(node.question_node, depth + 1)\n",
    "        else:\n",
    "            print(f\"{indent}Category: {node.name} [Leaf]\")\n",
    "\n",
    "# Uncomment to visualize structure\n",
    "#print_tree(root)\n",
    "\n",
    "\n",
    "#*******************************************************************************************************************************\n",
    "#Now that the tree structure has been created, populate the noun lists of each of the category leaf nodes with nouns that fit into\n",
    "#that category.\n",
    "\n",
    "import json\n",
    "\n",
    "# ==========================================\n",
    "# Load noun structures from previous step\n",
    "# ==========================================\n",
    "with open(\"noun_structures_clean.json\", \"r\") as f:\n",
    "    noun_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(noun_data)} noun structures.\")\n",
    "\n",
    "# ==========================================\n",
    "# Populate the leaf nodes \n",
    "# ==========================================\n",
    "\n",
    "for noun in noun_data:\n",
    "    try:\n",
    "        name = noun[\"name\"].strip()\n",
    "\n",
    "        # --- 1. Non-physical things ---\n",
    "        if not noun.get(\"is_physical\", False):\n",
    "            non_physical_things.noun_list.append(name)\n",
    "\n",
    "        # --- 2. People ---\n",
    "        if noun.get(\"is_person\", False):\n",
    "            people.noun_list.append(name)\n",
    "\n",
    "        # --- 3. Animals ---\n",
    "        if noun.get(\"is_animal\", False):\n",
    "            animals.noun_list.append(name)\n",
    "\n",
    "        # --- 4. Plants ---\n",
    "        if noun.get(\"is_plant\", False):\n",
    "            plants.noun_list.append(name)\n",
    "\n",
    "        # --- 5. Places ---\n",
    "        if noun.get(\"is_place\", False):\n",
    "            places.noun_list.append(name)\n",
    "\n",
    "        # --- 6. Foods ---\n",
    "        if noun.get(\"is_food\", False):\n",
    "            foods.noun_list.append(name)\n",
    "\n",
    "        # --- 7. Man-made objects ---\n",
    "        if noun.get(\"is_man_made\", False):\n",
    "            man_made_objects.noun_list.append(name)\n",
    "\n",
    "        # --- 8. Rocks ---\n",
    "        if noun.get(\"is_rock\", False):\n",
    "            rocks.noun_list.append(name)\n",
    "\n",
    "        # --- 9. Random living things ---\n",
    "        if (\n",
    "            noun.get(\"is_alive\", False)\n",
    "            and not noun.get(\"is_plant\", False)\n",
    "            and not noun.get(\"is_animal\", False)\n",
    "            and not noun.get(\"is_person\", False)\n",
    "        ):\n",
    "            random_living_things.noun_list.append(name)\n",
    "\n",
    "        # --- 10. Random uncategorized objects ---\n",
    "        if (\n",
    "            not noun.get(\"is_alive\", False)\n",
    "            and not noun.get(\"is_food\", False)\n",
    "            and not noun.get(\"is_man_made\", False)\n",
    "            and not noun.get(\"is_rock\", False)\n",
    "            and not noun.get(\"is_place\", False)\n",
    "        ):\n",
    "            random_uncategorized_objects.noun_list.append(name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing noun: {noun} -> {e}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Summary report\n",
    "# ==========================================\n",
    "def summarize_category(node):\n",
    "    print(f\"{node.name}: {len(node.noun_list)} nouns\")\n",
    "\n",
    "print(\"\\n=== Category Summary ===\")\n",
    "for cat in [\n",
    "    non_physical_things,\n",
    "    people,\n",
    "    animals,\n",
    "    plants,\n",
    "    random_living_things,\n",
    "    places,\n",
    "    foods,\n",
    "    man_made_objects,\n",
    "    rocks,\n",
    "    random_uncategorized_objects,\n",
    "]:\n",
    "    summarize_category(cat)\n",
    "\n",
    "\n",
    "# Optional: Write results to file for inspection\n",
    "all_category_data = {\n",
    "    \"non_physical_things\": non_physical_things.noun_list,\n",
    "    \"people\": people.noun_list,\n",
    "    \"animals\": animals.noun_list,\n",
    "    \"plants\": plants.noun_list,\n",
    "    \"random_living_things\": random_living_things.noun_list,\n",
    "    \"places\": places.noun_list,\n",
    "    \"foods\": foods.noun_list,\n",
    "    \"man_made_objects\": man_made_objects.noun_list,\n",
    "    \"rocks\": rocks.noun_list,\n",
    "    \"random_uncategorized_objects\": random_uncategorized_objects.noun_list,\n",
    "}\n",
    "\n",
    "with open(\"categorized_nouns.json\", \"w\") as f:\n",
    "    json.dump(all_category_data, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Categorized noun lists saved to 'categorized_nouns.json'\")\n",
    "\n",
    "\n",
    "\n",
    "#*****************************************************************************************************************************\n",
    "#Add properties to the leaf nodes for each category\n",
    "\n",
    "non_physical_things.properties = {\n",
    "    \"has\": [\"complexity\"],\n",
    "    \"is\": [\"a concept\"]\n",
    "}\n",
    "\n",
    "# 2.) People\n",
    "people.properties = {\n",
    "    \"has\": [\"entertainment\", \"influence\", \"scientific impact\", \"athletic ability\", \"medical knowledge\", \"sports scoring ability\"],\n",
    "    \"is\": [\"actor\", \"athlete\", \"STEM worker\", \"profession\"]\n",
    "}\n",
    "\n",
    "# 3.) Animals\n",
    "animals.properties = {\n",
    "    \"has\": [\"size\", \"speed\", \"aggressiveness\", \"domesticatability\"],\n",
    "    \"is\": [\"mammal\", \"bird\", \"reptile\", \"fish\", \"amphibian\"]\n",
    "}\n",
    "\n",
    "# 4.) Plants\n",
    "plants.properties = {\n",
    "    \"has\": [\"size\", \"beauty\", \"leaves\", \"fruit\"],\n",
    "    \"is\": [\"flower\", \"tree\", \"general plant or bush\"]\n",
    "}\n",
    "\n",
    "# 5.) Random living things\n",
    "random_living_things.properties = {\n",
    "    \"has\": [\"size\", \"speed\"],\n",
    "    \"is\": [\"air breathing\", \"water breathing\"]\n",
    "}\n",
    "\n",
    "# 6.) Places\n",
    "places.properties = {\n",
    "    \"has\": [\"heat\", \"extreme weather\", \"size\", \"cold\", \"population\", \"vegetation\"],\n",
    "    \"is\": [\"In the US\", \"In the western US\", \"In the Eastern US\", \"One Specific Place\"]\n",
    "}\n",
    "\n",
    "# 7.) Foods\n",
    "foods.properties = {\n",
    "    \"has\": [\"heat\", \"preparation time\", \"ingredients\", \"savoriness\", \"sweetness\", \"saltiness\"],\n",
    "    \"is\": [\"natural\", \"cooked\", \"raw\"]\n",
    "}\n",
    "\n",
    "# 8.) Man-made objects\n",
    "man_made_objects.properties = {\n",
    "    \"has\": [\"softness\", \"engineering\", \"electrical\", \"size\", \"monetary value\", \"simplicity\"],\n",
    "    \"is\": [\"tool\", \"vehicle\", \"toy\", \"service\", \"exercise\", \"clothing\"]\n",
    "}\n",
    "\n",
    "# 9.) Rocks\n",
    "rocks.properties = {\n",
    "    \"has\": [\"hardness\", \"brittleness\", \"shine\", \"beauty\", \"darkness\", \"monetary value\"],\n",
    "    \"is\": [\"rock\", \"mineral\", \"metal\"]\n",
    "}\n",
    "\n",
    "# 10.) Random uncategorized objects\n",
    "random_uncategorized_objects.properties = {\n",
    "    \"has\": [\"size\", \"complexity\", \"entertainment\"],\n",
    "    \"is\": [\"tool\", \"vehicle\", \"toy\", \"pokemon\", \"concept\"]\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# Optional: verify properties\n",
    "# ==========================================\n",
    "def print_leaf_properties(node):\n",
    "    print(f\"Category: {node.name}\")\n",
    "    print(f\"  has: {node.properties['has']}\")\n",
    "    print(f\"  is: {node.properties['is']}\\n\")\n",
    "\n",
    "for leaf in [\n",
    "    non_physical_things,\n",
    "    people,\n",
    "    animals,\n",
    "    plants,\n",
    "    random_living_things,\n",
    "    places,\n",
    "    foods,\n",
    "    man_made_objects,\n",
    "    rocks,\n",
    "    random_uncategorized_objects,\n",
    "]:\n",
    "    print_leaf_properties(leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0814b01-f195-4630-87b6-ed430031f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Loading tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6433c5a8eabe4196b262ce76e944ccbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380242a127014eb5886c99b4fac6adf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2c99f6457a422ea11ba444d3d8a208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177890e4ccc64556868426ddc3e65503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e53cb4f1b7747109f3d2e029c19a39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Loading model efficiently...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa061f71fc441cd8540c7e021741895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b452d8e47b4e4c2ba6e1a91b2c64eb83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d494efa27f4a1d86493e10a8d9ac03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86c8f8b589d4a70af70a9bec3b35436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128fb2ab153949188f6b4873b4fe9512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff55924c6234154b9c8b572ff014332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db318a0de9d047e59d43d40c183fe205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f3e85efaf94b25949f3a0f9c131c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ee541415f04902b6acf9d2e999bac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded on device: mps:0\n",
      "starting loop!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DynamicCache' object has no attribute 'seen_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 131\u001b[0m\n\u001b[1;32m    123\u001b[0m is_prompts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an expert at categorizing nouns. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe noun \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoun_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m belongs to the category \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleaf_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m is_props\n\u001b[1;32m    129\u001b[0m ]\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prompts:\n\u001b[0;32m--> 131\u001b[0m     bool_results \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbool\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prop, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(is_props, bool_results):\n\u001b[1;32m    133\u001b[0m         ratings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis\u001b[39m\u001b[38;5;124m\"\u001b[39m][prop] \u001b[38;5;241m=\u001b[39m val \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 80\u001b[0m, in \u001b[0;36mbatch_generate\u001b[0;34m(prompts, expected_type)\u001b[0m\n\u001b[1;32m     77\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompts, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[0;32m---> 80\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m decoded \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(outputs, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [parse_single_response(t, expected_type) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m decoded]\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/generation/utils.py:2564\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2561\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[1;32m   2563\u001b[0m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[0;32m-> 2564\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2565\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2566\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2570\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2571\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2572\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2574\u001b[0m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[1;32m   2575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2576\u001b[0m     generation_config\u001b[38;5;241m.\u001b[39mreturn_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result\u001b[38;5;241m.\u001b[39mpast_key_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_legacy_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2579\u001b[0m ):\n",
      "File \u001b[0;32m~/Library/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages/transformers/generation/utils.py:2781\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2777\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2779\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_unfinished_sequences(this_peer_finished, synced_gpus, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[1;32m   2780\u001b[0m     \u001b[38;5;66;03m# prepare model inputs\u001b[39;00m\n\u001b[0;32m-> 2781\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_inputs_for_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[1;32m   2784\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi_hyphen_3_hyphen_mini_hyphen_4k_hyphen_instruct/0a67737cc96d2554230f90338b163bc6380a2a85/modeling_phi3.py:1291\u001b[0m, in \u001b[0;36mPhi3ForCausalLM.prepare_inputs_for_generation\u001b[0;34m(self, input_ids, past_key_values, attention_mask, inputs_embeds, **kwargs)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(past_key_values, Cache):\n\u001b[1;32m   1290\u001b[0m     cache_length \u001b[38;5;241m=\u001b[39m past_key_values\u001b[38;5;241m.\u001b[39mget_seq_length()\n\u001b[0;32m-> 1291\u001b[0m     past_length \u001b[38;5;241m=\u001b[39m \u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseen_tokens\u001b[49m\n\u001b[1;32m   1292\u001b[0m     max_cache_length \u001b[38;5;241m=\u001b[39m past_key_values\u001b[38;5;241m.\u001b[39mget_max_length()\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DynamicCache' object has no attribute 'seen_tokens'"
     ]
    }
   ],
   "source": [
    "#DONT RUN THIS AS PART OF THE GAME THIS TAKES 10 HOURS TO RUN\n",
    "#This just generates further property ratings for each category\n",
    "\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# -------------------------------\n",
    "# Load model & tokenizer\n",
    "# -------------------------------\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "print(\"üöÄ Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(\"‚ö° Loading model efficiently...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\",          # uses GPU if available\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "device = next(model.parameters()).device\n",
    "print(f\"‚úÖ Model loaded on device: {device}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Helper: parse a single response\n",
    "# -------------------------------\n",
    "def parse_single_response(text, expected):\n",
    "    \"\"\"Extract a clean True/False or integer 0‚Äì10 from raw model output.\"\"\"\n",
    "    text = text.strip()\n",
    "\n",
    "    # Try to capture after \"Output:\" or \"Answer:\"\n",
    "    m = re.search(r\"(Output|Answer)\\s*[:\\-]\\s*([^\\n\\r]+)\", text, re.IGNORECASE)\n",
    "    if m:\n",
    "        val = m.group(2).strip()\n",
    "    else:\n",
    "        # Fallback to the last line or last token\n",
    "        lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
    "        val = lines[-1] if lines else text.strip()\n",
    "\n",
    "    val = val.strip(\" .,:;\\\"'`\")\n",
    "\n",
    "    if expected == \"bool\":\n",
    "        if val.lower().startswith((\"true\", \"yes\")):\n",
    "            return True\n",
    "        if val.lower().startswith((\"false\", \"no\")):\n",
    "            return False\n",
    "        return None\n",
    "    else:\n",
    "        m = re.search(r\"\\b([0-9]|10)\\b\", val)\n",
    "        if m:\n",
    "            return int(m.group(1))\n",
    "    return None\n",
    "\n",
    "# -------------------------------\n",
    "# Load nouns\n",
    "# -------------------------------\n",
    "with open(\"noun_structures_clean.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    noun_structures = json.load(f)\n",
    "\n",
    "noun_map = {n.get(\"name\", f\"unknown_{i}\"): n for i, n in enumerate(noun_structures)}\n",
    "\n",
    "# -------------------------------\n",
    "# Batched LLM querying\n",
    "# -------------------------------\n",
    "def batch_generate(prompts, expected_type):\n",
    "    \"\"\"Generate multiple prompts at once for speed.\"\"\"\n",
    "    if not prompts:\n",
    "        return []\n",
    "\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=16,\n",
    "            do_sample=False,\n",
    "            num_beams=1,\n",
    "            repetition_penalty=1.0,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return [parse_single_response(t, expected_type) for t in decoded]\n",
    "\n",
    "# -------------------------------\n",
    "# Main rating loop (batched)\n",
    "# -------------------------------\n",
    "BATCH_SIZE = 8  # tune higher (e.g., 16‚Äì32) for stronger GPUs\n",
    "\n",
    "# Ensure your leaf_nodes objects exist in this scope\n",
    "# e.g. defined in your earlier context\n",
    "leaf_nodes = [\n",
    "    non_physical_things,\n",
    "    people,\n",
    "    animals,\n",
    "    plants,\n",
    "    random_living_things,\n",
    "    places,\n",
    "    foods,\n",
    "    man_made_objects,\n",
    "    rocks,\n",
    "    random_uncategorized_objects,\n",
    "]\n",
    "\n",
    "counter = 0\n",
    "print(\"starting loop!\")\n",
    "for leaf in leaf_nodes:\n",
    "    leaf_name = getattr(leaf, \"name\", \"unknown category\")\n",
    "    is_props = getattr(leaf, \"properties\", {}).get(\"is\", [])\n",
    "    has_props = getattr(leaf, \"properties\", {}).get(\"has\", [])\n",
    "\n",
    "    for noun_name in getattr(leaf, \"noun_list\", []):\n",
    "        ratings = {\"is\": {}, \"has\": {}}\n",
    "\n",
    "        # ---- Batch all \"is\" prompts ----\n",
    "        is_prompts = [\n",
    "            f\"You are an expert at categorizing nouns. \"\n",
    "            f\"The noun '{noun_name}' belongs to the category '{leaf_name}'. \"\n",
    "            f\"Determine if this noun belongs to the property '{prop}'. \"\n",
    "            f\"Return ONLY True or False, nothing else.\"\n",
    "            for prop in is_props\n",
    "        ]\n",
    "        if is_prompts:\n",
    "            bool_results = batch_generate(is_prompts, \"bool\")\n",
    "            for prop, val in zip(is_props, bool_results):\n",
    "                ratings[\"is\"][prop] = val if val is not None else False\n",
    "\n",
    "        # ---- Batch all \"has\" prompts ----\n",
    "        has_prompts = [\n",
    "            f\"You are an expert at categorizing nouns. \"\n",
    "            f\"The noun '{noun_name}' belongs to the category '{leaf_name}'. \"\n",
    "            f\"Determine how much this noun has the property '{prop}' on a scale of 0-10. \"\n",
    "            f\"Return ONLY a single integer from 0 to 10, nothing else.\"\n",
    "            for prop in has_props\n",
    "        ]\n",
    "        if has_prompts:\n",
    "            int_results = batch_generate(has_prompts, \"int\")\n",
    "            for prop, val in zip(has_props, int_results):\n",
    "                ratings[\"has\"][prop] = val if val is not None else 0\n",
    "\n",
    "        noun_map[noun_name] = {\"name\": noun_name, **ratings}\n",
    "        counter += 1\n",
    "\n",
    "        # Progress and checkpointing\n",
    "        if counter % 20 == 0:\n",
    "            print(f\"Processed {counter} nouns...\")\n",
    "        if counter % 100 == 0:\n",
    "            with open(\"noun_structures_rated_progress.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(list(noun_map.values()), f, indent=2)\n",
    "\n",
    "# -------------------------------\n",
    "# Save final output\n",
    "# -------------------------------\n",
    "with open(\"noun_structures_rated.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(list(noun_map.values()), f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Done! Rated {counter} nouns and saved to 'noun_structures_rated.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "274cb1a8-15e5-4c9e-b724-331840d3d9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined 1841 rated nouns with clean data.\n",
      "‚ö†Ô∏è 0 nouns were missing rated data.\n",
      "üíæ Saved merged dataset as 'final_noun_tree.json'.\n"
     ]
    }
   ],
   "source": [
    "#DO NOT RUN THIS UNLESS THE PREVIOUS INPUT FILES CHANGE AND YOU NEED TO REGEN THE PROPERTIES\n",
    "#Combine the noun information together to construct the final tree to be used for gameplay\n",
    "#This makes a final .json file to use for the game \"final_noun_tree.json\"\n",
    "\n",
    "import json\n",
    "\n",
    "# -------------------------------\n",
    "# Load both JSON files\n",
    "# -------------------------------\n",
    "with open(\"noun_structures_clean.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    clean_data = json.load(f)\n",
    "\n",
    "with open(\"noun_structures_rated.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    rated_data = json.load(f)\n",
    "\n",
    "# -------------------------------\n",
    "# Build lookup for rated nouns\n",
    "# -------------------------------\n",
    "rated_map = {n.get(\"name\"): n for n in rated_data if \"name\" in n}\n",
    "\n",
    "combined_nouns = []\n",
    "merged_count = 0\n",
    "missing_rated = 0\n",
    "\n",
    "# -------------------------------\n",
    "# Merge the two datasets\n",
    "# -------------------------------\n",
    "for noun in clean_data:\n",
    "    name = noun.get(\"name\")\n",
    "    if not name:\n",
    "        continue\n",
    "\n",
    "    base = noun.copy()  # start from the clean data entry\n",
    "    rated = rated_map.get(name)\n",
    "\n",
    "    if rated:\n",
    "        # Merge the rated properties\n",
    "        base[\"is\"] = rated.get(\"is\", {})\n",
    "        base[\"has\"] = rated.get(\"has\", {})\n",
    "        merged_count += 1\n",
    "    else:\n",
    "        # Still include the noun even if it wasn‚Äôt rated\n",
    "        base[\"is\"] = {}\n",
    "        base[\"has\"] = {}\n",
    "        missing_rated += 1\n",
    "\n",
    "    combined_nouns.append(base)\n",
    "\n",
    "# -------------------------------\n",
    "# Save the combined output\n",
    "# -------------------------------\n",
    "with open(\"final_noun_tree.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(combined_nouns, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Combined {merged_count} rated nouns with clean data.\")\n",
    "print(f\"‚ö†Ô∏è {missing_rated} nouns were missing rated data.\")\n",
    "print(\"üíæ Saved merged dataset as 'final_noun_tree.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8436d9-a657-4477-8b4b-16a431637d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e6608-c4cf-4faf-88df-f326a4853a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b53fb19-d07a-4d6d-8986-4e858ea64534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1841 nouns from final_noun_tree.json\n",
      "Loaded 10 categories from categorized_nouns.json\n",
      "\n",
      "‚úÖ Final tree saved to 'final_full_tree.json'\n",
      "Total categories: 10\n",
      "Total nouns combined: 2442\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ===============================\n",
    "# Load the input JSON files\n",
    "# ===============================\n",
    "with open(\"final_noun_tree.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    noun_data = json.load(f)\n",
    "\n",
    "with open(\"categorized_nouns.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    categorized_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(noun_data)} nouns from final_noun_tree.json\")\n",
    "print(f\"Loaded {len(categorized_data)} categories from categorized_nouns.json\")\n",
    "\n",
    "# ===============================\n",
    "# Create lookup map for fast merge\n",
    "# ===============================\n",
    "noun_map = {n[\"name\"].strip().lower(): n for n in noun_data if \"name\" in n}\n",
    "\n",
    "# ===============================\n",
    "# Merge nouns into categories\n",
    "# ===============================\n",
    "final_tree = {}\n",
    "\n",
    "for category_name, noun_list in categorized_data.items():\n",
    "    merged_nouns = []\n",
    "    for noun_name in noun_list:\n",
    "        key = noun_name.strip().lower()\n",
    "        if key in noun_map:\n",
    "            merged_nouns.append(noun_map[key])\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: '{noun_name}' not found in final_noun_tree.json\")\n",
    "    final_tree[category_name] = {\n",
    "        \"name\": category_name,\n",
    "        \"noun_list\": merged_nouns\n",
    "    }\n",
    "\n",
    "# ===============================\n",
    "# Save the merged final structure\n",
    "# ===============================\n",
    "with open(\"final_full_tree.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_tree, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Final tree saved to 'final_full_tree.json'\")\n",
    "print(f\"Total categories: {len(final_tree)}\")\n",
    "total_nouns = sum(len(cat['noun_list']) for cat in final_tree.values())\n",
    "print(f\"Total nouns combined: {total_nouns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d03580-866c-46fa-be2a-e8dcb6b08e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final tree constructed in memory and saved to 'final_full_tree.pkl'\n",
      "Q: Is it physically tangible?\n",
      "  Yes ‚Üí physical_objects\n",
      "  Category: physical_objects ‚Üí has QuestionNode child\n",
      "    Q: Is it alive?\n",
      "      Yes ‚Üí living_things\n",
      "      Category: living_things ‚Üí has QuestionNode child\n",
      "        Q: Is it a person?\n",
      "          Yes ‚Üí people\n",
      "          Category: people [Leaf] ‚Üí 167 nouns\n",
      "            Nouns: actor, aeronautical engineer, air traffic controller, aircraft mechanic, allen iverson, anthony davis, architect, artisan, artist, astronaut ...\n",
      "          No  ‚Üí non_people\n",
      "          Category: non_people ‚Üí has QuestionNode child\n",
      "            Q: Is it an animal?\n",
      "              Yes ‚Üí animals\n",
      "              Category: animals [Leaf] ‚Üí 317 nouns\n",
      "                Nouns: aardvark, aerodactyl, african elephant, africatwin, airedale terrier, akita, alaskan malamute, alligator, alpaca, anaconda ...\n",
      "              No  ‚Üí non_animals\n",
      "              Category: non_animals ‚Üí has QuestionNode child\n",
      "                Q: Is it a plant?\n",
      "                  Yes ‚Üí plants\n",
      "                  Category: plants [Leaf] ‚Üí 134 nouns\n",
      "                    Nouns: acaiberry, apple, apple tree, apricot, avocado, avocado tree, azalea, bamboo, banana, banana plant ...\n",
      "                  No  ‚Üí random_living_things\n",
      "                  Category: random_living_things [Leaf] ‚Üí 5 nouns\n",
      "                    Nouns: baby, family, plankton, raincloud, sponge ...\n",
      "      No  ‚Üí non_living_things\n",
      "      Category: non_living_things ‚Üí has QuestionNode child\n",
      "        Q: Is it a place?\n",
      "          Yes ‚Üí places\n",
      "          Category: places [Leaf] ‚Üí 237 nouns\n",
      "            Nouns: airport, alabama, alaska, albuqerque, amazon rainforest, amazon river, american samoa, anchorage, apartment, archipelago ...\n",
      "          No  ‚Üí non_places\n",
      "          Category: non_places ‚Üí has QuestionNode child\n",
      "            Q: Is it a thing?\n",
      "              Yes ‚Üí things\n",
      "              Category: things ‚Üí has QuestionNode child\n",
      "                Q: Is it a food?\n",
      "                  Yes ‚Üí foods\n",
      "                  Category: foods [Leaf] ‚Üí 170 nouns\n",
      "                    Nouns: acaiberry, apple, apple pie, apricot, assisted dip, avocado, avocado tree, bagel, bagel with cream cheese, baguette ...\n",
      "                  No  ‚Üí non_foods\n",
      "                  Category: non_foods ‚Üí has QuestionNode child\n",
      "                    Q: Is it man made?\n",
      "                      Yes ‚Üí man_made_objects\n",
      "                      Category: man_made_objects [Leaf] ‚Üí 1097 nouns\n",
      "                        Nouns: action figure, actor, adobe, advanced microscopy, aeronautical engineer, agility ladder drills, airplane, air traffic controller, aircraft mechanic, airedale terrier ...\n",
      "                      No  ‚Üí natural_things\n",
      "                      Category: natural_things ‚Üí has QuestionNode child\n",
      "                        Q: Is it a rock or mineral?\n",
      "                          Yes ‚Üí rocks\n",
      "                          Category: rocks [Leaf] ‚Üí 125 nouns\n",
      "                            Nouns: agate, amazonite, amethyst, amphibolite, andesite, anorthosite, anthracite, apatite, aquamarine, aragonite ...\n",
      "                          No  ‚Üí random_uncategorized_objects\n",
      "                          Category: random_uncategorized_objects [Leaf] ‚Üí 189 nouns\n",
      "                            Nouns: aerodactyl, africatwin, air start unit, airspace, angelite, appearance, articuno, atmosphere, bad-weather, basenji ...\n",
      "              No  ‚Üí non_physical_things\n",
      "              Category: non_physical_things [Leaf] ‚Üí 1 nouns\n",
      "                Nouns: desertx ...\n",
      "  No  ‚Üí non_physical_things\n",
      "  Category: non_physical_things [Leaf] ‚Üí 1 nouns\n",
      "    Nouns: desertx ...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# -----------------------------\n",
    "# Node classes\n",
    "# -----------------------------\n",
    "class CategoryNode:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.properties = {}        # holds 'is' and 'has' property lists\n",
    "        self.question_node = None   # points to a QuestionNode if there are questions below\n",
    "        self.noun_list = []         # used if leaf node\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"CategoryNode({self.name})\"\n",
    "\n",
    "\n",
    "class QuestionNode:\n",
    "    def __init__(self, question):\n",
    "        self.question = question\n",
    "        self.yes = None   # must point to CategoryNode\n",
    "        self.no = None    # must point to CategoryNode\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"QuestionNode({self.question})\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Leaf categories\n",
    "# -----------------------------\n",
    "non_physical_things = CategoryNode(\"non_physical_things\")\n",
    "people = CategoryNode(\"people\")\n",
    "animals = CategoryNode(\"animals\")\n",
    "plants = CategoryNode(\"plants\")\n",
    "random_living_things = CategoryNode(\"random_living_things\")\n",
    "places = CategoryNode(\"places\")\n",
    "foods = CategoryNode(\"foods\")\n",
    "man_made_objects = CategoryNode(\"man_made_objects\")\n",
    "rocks = CategoryNode(\"rocks\")\n",
    "random_uncategorized_objects = CategoryNode(\"random_uncategorized_objects\")\n",
    "\n",
    "# -----------------------------\n",
    "# Internal categories\n",
    "# -----------------------------\n",
    "physical_objects = CategoryNode(\"physical_objects\")\n",
    "living_things = CategoryNode(\"living_things\")\n",
    "non_living_things = CategoryNode(\"non_living_things\")\n",
    "non_people = CategoryNode(\"non_people\")\n",
    "non_animals = CategoryNode(\"non_animals\")\n",
    "non_places = CategoryNode(\"non_places\")\n",
    "things = CategoryNode(\"things\")\n",
    "non_foods = CategoryNode(\"non_foods\")\n",
    "natural_things = CategoryNode(\"natural_things\")\n",
    "\n",
    "# -----------------------------\n",
    "# Question nodes\n",
    "# -----------------------------\n",
    "q_is_tangible = QuestionNode(\"Is it physically tangible?\")\n",
    "q_is_alive = QuestionNode(\"Is it alive?\")\n",
    "q_is_person = QuestionNode(\"Is it a person?\")\n",
    "q_is_animal = QuestionNode(\"Is it an animal?\")\n",
    "q_is_plant = QuestionNode(\"Is it a plant?\")\n",
    "q_is_place = QuestionNode(\"Is it a place?\")\n",
    "q_is_thing = QuestionNode(\"Is it a thing?\")\n",
    "q_is_food = QuestionNode(\"Is it a food?\")\n",
    "q_is_man_made = QuestionNode(\"Is it man made?\")\n",
    "q_is_rock = QuestionNode(\"Is it a rock or mineral?\")\n",
    "\n",
    "# -----------------------------\n",
    "# Link tree nodes\n",
    "# -----------------------------\n",
    "root = q_is_tangible\n",
    "q_is_tangible.yes = physical_objects\n",
    "q_is_tangible.no = non_physical_things\n",
    "\n",
    "physical_objects.question_node = q_is_alive\n",
    "q_is_alive.yes = living_things\n",
    "q_is_alive.no = non_living_things\n",
    "\n",
    "living_things.question_node = q_is_person\n",
    "q_is_person.yes = people\n",
    "q_is_person.no = non_people\n",
    "\n",
    "non_people.question_node = q_is_animal\n",
    "q_is_animal.yes = animals\n",
    "q_is_animal.no = non_animals\n",
    "\n",
    "non_animals.question_node = q_is_plant\n",
    "q_is_plant.yes = plants\n",
    "q_is_plant.no = random_living_things\n",
    "\n",
    "non_living_things.question_node = q_is_place\n",
    "q_is_place.yes = places\n",
    "q_is_place.no = non_places\n",
    "\n",
    "non_places.question_node = q_is_thing\n",
    "q_is_thing.yes = things\n",
    "q_is_thing.no = non_physical_things  # loop back intentionally\n",
    "\n",
    "things.question_node = q_is_food\n",
    "q_is_food.yes = foods\n",
    "q_is_food.no = non_foods\n",
    "\n",
    "non_foods.question_node = q_is_man_made\n",
    "q_is_man_made.yes = man_made_objects\n",
    "q_is_man_made.no = natural_things\n",
    "\n",
    "natural_things.question_node = q_is_rock\n",
    "q_is_rock.yes = rocks\n",
    "q_is_rock.no = random_uncategorized_objects\n",
    "\n",
    "# -----------------------------\n",
    "# Load categorized nouns with full properties\n",
    "# -----------------------------\n",
    "with open(\"final_noun_tree.json\", \"r\") as f:\n",
    "    noun_data = json.load(f)\n",
    "\n",
    "# Map categories to leaf nodes\n",
    "leaf_mapping = {\n",
    "    \"non_physical_things\": non_physical_things,\n",
    "    \"people\": people,\n",
    "    \"animals\": animals,\n",
    "    \"plants\": plants,\n",
    "    \"random_living_things\": random_living_things,\n",
    "    \"places\": places,\n",
    "    \"foods\": foods,\n",
    "    \"man_made_objects\": man_made_objects,\n",
    "    \"rocks\": rocks,\n",
    "    \"random_uncategorized_objects\": random_uncategorized_objects,\n",
    "}\n",
    "\n",
    "# Populate noun lists in leaves according to their category\n",
    "for cat_name, leaf_node in leaf_mapping.items():\n",
    "    for noun in noun_data:\n",
    "        # Determine which nouns belong in this category\n",
    "        include = False\n",
    "        if cat_name == \"non_physical_things\" and not noun.get(\"is_physical\", False):\n",
    "            include = True\n",
    "        elif cat_name == \"people\" and noun.get(\"is_person\", False):\n",
    "            include = True\n",
    "        elif cat_name == \"animals\" and noun.get(\"is_animal\", False):\n",
    "            include = True\n",
    "        elif cat_name == \"plants\" and noun.get(\"is_plant\", False):\n",
    "            include = True\n",
    "        elif cat_name == \"random_living_things\" and noun.get(\"is_alive\", False) and not noun.get(\"is_person\", False) and not noun.get(\"is_animal\", False) and not noun.get(\"is_plant\", False):\n",
    "            include = True\n",
    "        elif cat_name == \"places\" and noun.get(\"is_place\", False):\n",
    "            include = True\n",
    "        elif cat_name == \"foods\" and noun.get(\"is_food\", False):\n",
    "            include = True\n",
    "        elif cat_name == \"man_made_objects\" and noun.get(\"is_man_made\", False):\n",
    "            include = True\n",
    "        elif cat_name == \"rocks\" and noun.get(\"is_rock\", False):\n",
    "            include = True\n",
    "        elif cat_name == \"random_uncategorized_objects\" and not noun.get(\"is_alive\", False) and not noun.get(\"is_food\", False) and not noun.get(\"is_man_made\", False) and not noun.get(\"is_rock\", False) and not noun.get(\"is_place\", False):\n",
    "            include = True\n",
    "\n",
    "        if include:\n",
    "            leaf_node.noun_list.append(noun)\n",
    "\n",
    "# -----------------------------\n",
    "# Define properties for leaves\n",
    "# -----------------------------\n",
    "non_physical_things.properties = {\"is\": [\"a concept\"], \"has\": [\"complexity\"]}\n",
    "people.properties = {\"is\": [\"actor\",\"athlete\",\"STEM worker\",\"profession\"], \"has\": [\"entertainment\",\"influence\",\"scientific impact\",\"athletic ability\",\"medical knowledge\",\"sports scoring ability\"]}\n",
    "animals.properties = {\"is\": [\"mammal\",\"bird\",\"reptile\",\"fish\",\"amphibian\"], \"has\": [\"size\",\"speed\",\"aggressiveness\",\"domesticatability\"]}\n",
    "plants.properties = {\"is\": [\"flower\",\"tree\",\"general plant or bush\"], \"has\": [\"size\",\"beauty\",\"leaves\",\"fruit\"]}\n",
    "random_living_things.properties = {\"is\": [\"air breathing\",\"water breathing\"], \"has\": [\"size\",\"speed\"]}\n",
    "places.properties = {\"is\": [\"In the US\",\"In the western US\",\"In the Eastern US\",\"One Specific Place\"], \"has\": [\"heat\",\"extreme weather\",\"size\",\"cold\",\"population\",\"vegetation\"]}\n",
    "foods.properties = {\"is\": [\"natural\",\"cooked\",\"raw\"], \"has\": [\"heat\",\"preparation time\",\"ingredients\",\"savoriness\",\"sweetness\",\"saltiness\"]}\n",
    "man_made_objects.properties = {\"is\": [\"tool\",\"vehicle\",\"toy\",\"service\",\"exercise\",\"clothing\"], \"has\": [\"softness\",\"engineering\",\"electrical\",\"size\",\"monetary value\",\"simplicity\"]}\n",
    "rocks.properties = {\"is\": [\"rock\",\"mineral\",\"metal\"], \"has\": [\"hardness\",\"brittleness\",\"shine\",\"beauty\",\"darkness\",\"monetary value\"]}\n",
    "random_uncategorized_objects.properties = {\"is\": [\"tool\",\"vehicle\",\"toy\",\"pokemon\",\"concept\"], \"has\": [\"size\",\"complexity\",\"entertainment\"]}\n",
    "\n",
    "# -----------------------------\n",
    "# Save final tree for inspection\n",
    "# -----------------------------\n",
    "import pickle\n",
    "with open(\"final_full_tree.pkl\", \"wb\") as f:\n",
    "    pickle.dump(root, f)\n",
    "\n",
    "print(\"‚úÖ Final tree constructed in memory and saved to 'final_full_tree.pkl'\")\n",
    "\n",
    "def visualize_tree(node, depth=0, show_nouns=False):\n",
    "    \"\"\"\n",
    "    Recursively visualize the tree structure.\n",
    "    \n",
    "    Args:\n",
    "        node: CategoryNode or QuestionNode\n",
    "        depth: Current depth in the tree for indentation\n",
    "        show_nouns: If True, print the nouns in each leaf node\n",
    "    \"\"\"\n",
    "    indent = \"  \" * depth\n",
    "    if isinstance(node, QuestionNode):\n",
    "        print(f\"{indent}Q: {node.question}\")\n",
    "        if node.yes:\n",
    "            print(f\"{indent}  Yes ‚Üí {node.yes.name if isinstance(node.yes, CategoryNode) else node.yes.question}\")\n",
    "            visualize_tree(node.yes, depth + 1, show_nouns)\n",
    "        if node.no:\n",
    "            print(f\"{indent}  No  ‚Üí {node.no.name if isinstance(node.no, CategoryNode) else node.no.question}\")\n",
    "            visualize_tree(node.no, depth + 1, show_nouns)\n",
    "    elif isinstance(node, CategoryNode):\n",
    "        if node.question_node:\n",
    "            print(f\"{indent}Category: {node.name} ‚Üí has QuestionNode child\")\n",
    "            visualize_tree(node.question_node, depth + 1, show_nouns)\n",
    "        else:\n",
    "            print(f\"{indent}Category: {node.name} [Leaf] ‚Üí {len(node.noun_list)} nouns\")\n",
    "            if show_nouns and node.noun_list:\n",
    "                # extract the 'name' field from each noun dict\n",
    "                noun_names = [n[\"name\"] for n in node.noun_list[:10]]\n",
    "                print(f\"{indent}  Nouns: {', '.join(noun_names)} ...\")\n",
    "\n",
    "# Example usage\n",
    "visualize_tree(root, show_nouns=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf7b7f97-1453-423c-9a97-235f3a892dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it physically tangible?\n"
     ]
    }
   ],
   "source": [
    "current = root\n",
    "print(current.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a2b6451-fa32-43df-8770-3b4639300024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physical_objects\n"
     ]
    }
   ],
   "source": [
    "current = current.yes\n",
    "print(current.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a7e7ad8-efb2-4a6d-a7e5-3a14a2986741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it alive?\n"
     ]
    }
   ],
   "source": [
    "print(current.question_node.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8afadcf8-f0da-4f30-9f0b-04c18b3ae2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "living_things\n"
     ]
    }
   ],
   "source": [
    "current = current.question_node.yes\n",
    "print(current.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1616a4b-df90-4897-b2bf-51a7b7fdef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it a person?\n"
     ]
    }
   ],
   "source": [
    "print(current.question_node.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "356b5697-9754-43df-b9ee-850c1912f49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Is it physically tangible? (y/n)  y\n",
      "Is it alive? (y/n)  y\n",
      "Is it a person? (y/n)  n\n",
      "Is it an animal? (y/n)  y\n",
      "Does your word have the property 'mammal'? (y/n)  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I could not guess your word. Possible options: []...\n"
     ]
    }
   ],
   "source": [
    "current = root\n",
    "questions_asked = 0\n",
    "MAX_QUESTIONS = 20\n",
    "\n",
    "# Step 1: Traverse tree to leaf node\n",
    "while True:\n",
    "    if isinstance(current, QuestionNode):\n",
    "        ans = input(f\"{current.question} (y/n) \").strip().lower()\n",
    "        if ans in (\"y\", \"yes\"):\n",
    "            current = current.yes\n",
    "        else:\n",
    "            current = current.no\n",
    "        questions_asked += 1\n",
    "    elif isinstance(current, CategoryNode):\n",
    "        if current.question_node:\n",
    "            current = current.question_node\n",
    "        else:\n",
    "            # Leaf node reached\n",
    "            break\n",
    "\n",
    "# Step 2: Ask 'is' property questions on leaf node\n",
    "for prop in current.properties.get(\"is\", []):\n",
    "    ans = input(f\"Does your word have the property '{prop}'? (y/n) \").strip().lower()\n",
    "    if ans in (\"y\", \"yes\"):\n",
    "        current.noun_list = [\n",
    "            noun for noun in current.noun_list if noun.get(prop, False)\n",
    "        ]\n",
    "        break  # Only one 'yes' needed\n",
    "    questions_asked += 1\n",
    "\n",
    "# Step 3: Ask 'has' property questions (numerical)\n",
    "for prop in current.properties.get(\"has\", []):\n",
    "    if len(current.noun_list) <= 1 or questions_asked >= MAX_QUESTIONS:\n",
    "        break\n",
    "    # Sort nouns by property\n",
    "    sorted_nouns = sorted(current.noun_list, key=lambda x: x.get(prop, 0))\n",
    "    median_noun = sorted_nouns[len(sorted_nouns)//2]\n",
    "    ans = input(f\"Is your word more '{prop}' than '{median_noun['name']}'? (y/n) \").strip().lower()\n",
    "    if ans in (\"y\", \"yes\"):\n",
    "        current.noun_list = [\n",
    "            noun for noun in current.noun_list if noun.get(prop, 0) > median_noun.get(prop, 0)\n",
    "        ]\n",
    "    else:\n",
    "        current.noun_list = [\n",
    "            noun for noun in current.noun_list if noun.get(prop, 0) <= median_noun.get(prop, 0)\n",
    "        ]\n",
    "    questions_asked += 1\n",
    "\n",
    "# Step 4: Make final guess\n",
    "if len(current.noun_list) == 1:\n",
    "    print(f\"My guess is: {current.noun_list[0]['name']}\")\n",
    "else:\n",
    "    print(f\"I could not guess your word. Possible options: {[n['name'] for n in current.noun_list[:5]]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481a7650-ae06-4fa0-a7c9-8d2ffb825789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
